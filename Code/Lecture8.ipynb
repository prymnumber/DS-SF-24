{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  prestige\n",
      "0      0  380  3.61         3\n",
      "1      1  660  3.67         3\n",
      "2      1  800  4.00         1\n",
      "3      1  640  3.19         4\n",
      "4      0  520  2.93         4\n",
      "            admit         gre         gpa    prestige\n",
      "count  397.000000  397.000000  397.000000  397.000000\n",
      "mean     0.317380  587.858942    3.392242    2.488665\n",
      "std      0.466044  115.717787    0.380208    0.947083\n",
      "min      0.000000  220.000000    2.260000    1.000000\n",
      "25%      0.000000  520.000000    3.130000    2.000000\n",
      "50%      0.000000  580.000000    3.400000    2.000000\n",
      "75%      1.000000  660.000000    3.670000    3.000000\n",
      "max      1.000000  800.000000    4.000000    4.000000\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/ga-students/DS-SF-24/master/Data/admissions.csv\"\n",
    "AdmissionData = pd.read_csv(url)\n",
    "\n",
    "# Let's get rid of Missing values - there are only a few missing values so, let's drop them all\n",
    "AdmissionData.dropna(inplace = True)\n",
    "print(AdmissionData.head(5))\n",
    "print(AdmissionData.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige  prestige_1.0  prestige_2.0  prestige_3.0\n",
       "0      0  380  3.61         3             0             0             1\n",
       "1      1  660  3.67         3             0             0             1\n",
       "2      1  800  4.00         1             1             0             0\n",
       "3      1  640  3.19         4             0             0             0\n",
       "4      0  520  2.93         4             0             0             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrestigeDummy = pd.get_dummies(AdmissionData['prestige'], prefix = 'prestige')\n",
    "del PrestigeDummy['prestige_4.0']\n",
    "AdmissionData = pd.concat([AdmissionData, PrestigeDummy], axis=1)\n",
    "AdmissionData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's first use our favorite statsmodels.api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One of the issues with StatsModels api is that it does not generate intercept automatically\n",
    "\n",
    "#### In order to add intercept you need to add a column with all values of 1 to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AdmissionData['Intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y = AdmissionData['admit']\n",
    "X = AdmissionData[['Intercept','gre','gpa','prestige_1.0','prestige_2.0','prestige_3.0']]\n",
    "\n",
    "logit = sm.Logit(y, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 04 Jul 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:46:10</td>     <th>  Log-Likelihood:    </th> <td> -227.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.176e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   -5.4303</td> <td>    1.140</td> <td>   -4.764</td> <td> 0.000</td> <td>   -7.664    -3.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0022</td> <td>    0.001</td> <td>    2.028</td> <td> 0.043</td> <td> 7.44e-05     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.7793</td> <td>    0.333</td> <td>    2.344</td> <td> 0.019</td> <td>    0.128     1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_1.0</th> <td>    1.5534</td> <td>    0.417</td> <td>    3.721</td> <td> 0.000</td> <td>    0.735     2.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>    0.8733</td> <td>    0.367</td> <td>    2.378</td> <td> 0.017</td> <td>    0.153     1.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>    0.2147</td> <td>    0.393</td> <td>    0.547</td> <td> 0.584</td> <td>   -0.555     0.984</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Mon, 04 Jul 2016   Pseudo R-squ.:                 0.08166\n",
       "Time:                        11:46:10   Log-Likelihood:                -227.82\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.176e-07\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       -5.4303      1.140     -4.764      0.000        -7.664    -3.196\n",
       "gre              0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
       "gpa              0.7793      0.333      2.344      0.019         0.128     1.431\n",
       "prestige_1.0     1.5534      0.417      3.721      0.000         0.735     2.372\n",
       "prestige_2.0     0.8733      0.367      2.378      0.017         0.153     1.593\n",
       "prestige_3.0     0.2147      0.393      0.547      0.584        -0.555     0.984\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept       0.000002\n",
      "gre             0.042558\n",
      "gpa             0.019090\n",
      "prestige_1.0    0.000198\n",
      "prestige_2.0    0.017420\n",
      "prestige_3.0    0.584373\n",
      "dtype: float64\n",
      "Intercept      -5.430265\n",
      "gre             0.002218\n",
      "gpa             0.779337\n",
      "prestige_1.0    1.553411\n",
      "prestige_2.0    0.873274\n",
      "prestige_3.0    0.214733\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result.pvalues)\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we learn from these coefficients?\n",
    "\n",
    "Higher GPA and higher GRE adds to odds of admission. The same story is true for prestige. The higher the prestige of your undergraduate school the more your chance of getting admitted. We are going to interpret the coefficients in more detail later. To be more precise, keeping everything else constant, 1 point increase in GRE adds to the odds of acceptance 0.22%. Or 1 point better GPA leads to 80% more odds of acceptance. Or in coparison to Prestige 4 universities, graduating from a tier 1 universiy, adds to odds of admission 155% (or exp(1.55) - 1)%.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's use SKlearn library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "y = AdmissionData['admit']\n",
    "X = AdmissionData[['gre','gpa','prestige_1.0','prestige_2.0','prestige_3.0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.58889206e-03   1.84632255e-04   1.16761197e+00   5.26947990e-01\n",
      "   -3.80822672e-02]]\n",
      "[-2.07018745]\n"
     ]
    }
   ],
   "source": [
    "lm.fit(X,y)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare these results with statsmodels api. Numbers are totally different! That's because of the numerical varaibles used to optimize these algorithms. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.58889206e-03   1.84632255e-04   1.16761197e+00   5.26947990e-01\n",
      "   -3.80822672e-02]]\n",
      "[-2.07018745]\n"
     ]
    }
   ],
   "source": [
    "# The default setting is 'liblinear' method\n",
    "# Only use it when you want to use something like Lasso Regression we learned for \n",
    "# Selection Models in Linear Regression\n",
    "# Also for multi-class problems you cannot use 'liblinear'\n",
    "lm = LogisticRegression(solver = 'liblinear', max_iter = 10000)\n",
    "lm.fit(X,y)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00233152  0.70792286  1.27434358  0.65974014  0.02878075]]\n",
      "[-5.06243972]\n"
     ]
    }
   ],
   "source": [
    "# If you want to use Logistic Regression for interpretation and do not intend to \n",
    "# do regularization , i.e. shirinking coefficients using Lasso type methods which is called L1 penalty, \n",
    "# then use 'newton-cg' or 'lbfgs'\n",
    "# You can also use 'newton-cg' or 'lbfgs' for multi-class problems\n",
    "# Compare this result with StatsModels api. They are pretty close\n",
    "lm = LogisticRegression(solver = 'newton-cg', max_iter = 10000)\n",
    "lm.fit(X,y)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00233148  0.70782152  1.27434849  0.65977     0.02877124]]\n",
      "[-5.06208165]\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression(solver = 'lbfgs', max_iter  = 10000)\n",
    "lm.fit(X,y)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student A and Student B are graduated from same school, have same background and same GPA. The only difference between the two is their GRE score. Student A's GRE is 50 scores better. What is the difference of odds of admission for these two students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studen A has 12.36 percent better odds than Student B\n"
     ]
    }
   ],
   "source": [
    "print(\"Studen A has %.2f percent better odds than Student B\" %((np.exp(50*0.00233 ) - 1) *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the probability of a student who came from a second tier school to get admitted to UCLA if her GPA is 3.5, GRE Score is 650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[ 0.60096158  0.39903842]]\n"
     ]
    }
   ],
   "source": [
    "x1 = [[650,3.5,0,1,0]]\n",
    "print(lm.predict(x1))  #It is more likely that she will not get admitted\n",
    "print(lm.predict_proba(x1)) #Probability of Admission is  39.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's calculate cross-validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697410881801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "print(cross_val_score(lm,X,y,cv=10, scoring = 'accuracy').mean())\n",
    "#cross_val_score(model,inputs,output,cv = k-fold).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[253,  18],\n",
       "       [ 99,  27]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_hat = lm.predict(X)\n",
    "confusion_matrix(y, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcty Predicted Not Admit = 253\n",
      "Correcty Predicted Admit = 27\n",
      "Mistakenly Predicted Not Admit = 99\n",
      "Mistakenly Predicted Admit = 18\n"
     ]
    }
   ],
   "source": [
    "Correctly_Predicted_NotAdmit = sum((y == 0) & (y_hat == 0))\n",
    "Correctly_Predicted_Admit = sum((y == 1) & (y_hat == 1))\n",
    "Mistakenly_Predicted_NotAdmit = sum((y == 1) & (y_hat == 0))\n",
    "Mistakenly_Predicted_Admit = sum((y == 0) & (y_hat == 1))\n",
    "\n",
    "\n",
    "print(\"Correcty Predicted Not Admit = %.f\" %Correctly_Predicted_NotAdmit)\n",
    "print(\"Correcty Predicted Admit = %.f\" %Correctly_Predicted_Admit)\n",
    "print(\"Mistakenly Predicted Not Admit = %.f\" %Mistakenly_Predicted_NotAdmit)\n",
    "print(\"Mistakenly Predicted Admit = %.f\" %Mistakenly_Predicted_Admit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try testing and plotting CV Scores with different C values. C valuse world like alpha in Linear Regression Models. penalty = 'l1' works like Lasso and penalty = 'l2' works like Ridge penalty. You can only use 'l1' penalty if your solver = ‘liblinear’. For solver = ‘newton-cg’ and solver = ‘lbfgs’, you can only use 'l2' penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's Standardize our outputs first\n",
    "def Standardize(X):\n",
    "    X_Max = X.max()\n",
    "    X_Min = X.min()\n",
    "    X_Standardized = (X-X_Min)/(X_Max - X_Min)\n",
    "    return X_Standardized\n",
    "\n",
    "AdmissionData['gre_Standardized'] = Standardize(AdmissionData.gre)\n",
    "AdmissionData['gpa_Standardized'] = Standardize(AdmissionData.gpa)\n",
    "\n",
    "y = AdmissionData['admit']\n",
    "X = AdmissionData[['gre_Standardized','gpa_Standardized','prestige_1.0','prestige_2.0','prestige_3.0']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's first try L1 penalty - we need to use solver = ‘liblinear’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nahgIkiTAQJAkNQwESRIA/x87gAXz5d3zpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111ad3610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our optimal C is 1.000000\n",
      "Our accuracy at optimal C is 0.709850\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Try testing and plot\n",
    "c_list = np.logspace(-10,10,21) \n",
    "c_index = np.linspace(-10,10,21)\n",
    "#C is just the inverse of Lambda - the smaller the C - the stronger the\n",
    "#regulatization. The smaller C's choose less variables\n",
    "cv_scores = []\n",
    "for c_score in c_list:\n",
    "    lm = LogisticRegression(C = c_score,  solver = 'liblinear', max_iter  = 10000, penalty = 'l1')\n",
    "    cv_scores.append(cross_val_score(lm, X, y,cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(c_index, cv_scores)\n",
    "plt.show()\n",
    "\n",
    "print(\"Our optimal C is %f\" %c_list[np.argmax(cv_scores)])   \n",
    "print(\"Our accuracy at optimal C is %f\" %np.max(cv_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87082998  1.02547448  1.25335171  0.59895604  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression(C = 1,  solver = 'liblinear', max_iter  = 10000, penalty = 'l1')\n",
    "lm.fit(X,y)\n",
    "print(lm.coef_)\n",
    "\n",
    "# We can see that prestige_3 was shrunk to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nldOf78R2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e6e18d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our optimal C is 1.281818\n",
      "Our accuracy at optimal C is 0.712414\n"
     ]
    }
   ],
   "source": [
    "### You can localize your search once you have an idea of where to search for the optimal solution\n",
    "\n",
    "c_list = np.linspace(0.1,4,100) \n",
    "cv_scores = []\n",
    "for c_score in c_list:\n",
    "    lm = LogisticRegression(C = c_score,  solver = 'liblinear', max_iter  = 10000, penalty = 'l1')\n",
    "    cv_scores.append(cross_val_score(lm, X, y,cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(c_list, cv_scores)\n",
    "plt.show()\n",
    "\n",
    "print(\"Our optimal C is %f\" %c_list[np.argmax(cv_scores)])   \n",
    "print(\"Our accuracy at optimal C is %f\" %np.max(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now try l2 penalty using solver = ‘newton-cg’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQD/HzAbnbKEd2TAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1134ebe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our optimal C is 1.000000\n",
      "Our accuracy at optimal C is 0.707414\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Try testing and plot\n",
    "c_list = np.logspace(-10,10,21) \n",
    "c_index = np.linspace(-10,10,21)\n",
    "#C is just the inverse of Lambda - the smaller the C - the stronger the\n",
    "#regulatization. The smaller C's choose less variables\n",
    "cv_scores = []\n",
    "for c_score in c_list:\n",
    "    lm = LogisticRegression(C = c_score,  solver = 'newton-cg', max_iter  = 10000, penalty = 'l2')\n",
    "    cv_scores.append(cross_val_score(lm, X, y,cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(c_index, cv_scores)\n",
    "plt.show()\n",
    "\n",
    "print(\"Our optimal C is %f\" %c_list[np.argmax(cv_scores)])   \n",
    "print(\"Our accuracy at optimal C is %f\" %np.max(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.03528518  1.12595352  1.2867772   0.66687786  0.0385698 ]]\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression(C = 1,  solver = 'newton-cg', max_iter  = 10000, penalty = 'l2')\n",
    "lm.fit(X,y)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHAJmZiXmEDAzKzGHgJlZiTkEzMxK7P8DZTbA3ClffigAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113499b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our optimal C is 0.446465\n",
      "Our accuracy at optimal C is 0.709975\n"
     ]
    }
   ],
   "source": [
    "### Let's localize our seach \n",
    "c_list = np.linspace(.1,5,100)\n",
    "#C is just the inverse of Lambda - the smaller the C - the stronger the\n",
    "#regulatization. The smaller C's choose less variables\n",
    "cv_scores = []\n",
    "for c_score in c_list:\n",
    "    lm = LogisticRegression(C = c_score,  solver = 'newton-cg', max_iter  = 10000, pbenalty = 'l2')\n",
    "    cv_scores.append(cross_val_score(lm, X, y,cv = 10, scoring = 'accuracy').mean())\n",
    "\n",
    "plt.plot(c_list, cv_scores)\n",
    "plt.show()\n",
    "\n",
    "print(\"Our optimal C is %f\" %c_list[np.argmax(cv_scores)])   \n",
    "print(\"Our accuracy at optimal C is %f\" %np.max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
